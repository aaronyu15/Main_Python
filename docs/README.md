# Spiking Neural Network for Optical Flow Estimation

**Thesis Project: FPGA-Ready Spiking Neural Network for Event-Based Optical Flow**

This repository contains a complete implementation of a Spiking Neural Network (SNN) for optical flow estimation, designed for eventual deployment on FPGAs. The framework supports quantization-aware training with progressive bit-width reduction, enabling efficient hardware implementation.

## ğŸ¯ Project Overview

- **Goal**: Train a spiking neural network for optical flow estimation that can be deployed on FPGAs
- **Key Features**:
  - Event-based optical flow estimation using SNNs
  - Quantization-aware training (32-bit â†’ 8-bit â†’ 4-bit â†’ 1-bit)
  - Binary SNN support for extreme efficiency
  - Modular architecture for easy experimentation
  - Hardware-aware design with sparsity constraints

## ğŸ“ Project Structure

```
Main_Python/
â”œâ”€â”€ snn/                          # Main package
â”‚   â”œâ”€â”€ models/                   # Neural network models
â”‚   â”‚   â”œâ”€â”€ snn_layers.py        # LIF neurons, spiking convolutions
â”‚   â”‚   â””â”€â”€ spiking_flownet.py   # FlowNet architecture for SNNs
â”‚   â”œâ”€â”€ quantization/            # Quantization utilities
â”‚   â”‚   â”œâ”€â”€ quantization_aware.py # QAT layers and methods
â”‚   â”‚   â””â”€â”€ binary_layers.py     # Binary/XNOR layers for FPGA
â”‚   â”œâ”€â”€ data/                    # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ optical_flow_dataset.py
â”‚   â”‚   â””â”€â”€ data_utils.py
â”‚   â”œâ”€â”€ training/                # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Main training loop
â”‚   â”‚   â””â”€â”€ losses.py            # Loss functions
â”‚   â”œâ”€â”€ utils/                   # Utilities
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging and tensorboard
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚   â”‚   â””â”€â”€ visualization.py     # Flow visualization
â”‚   â””â”€â”€ configs/                 # Configuration files
â”‚       â”œâ”€â”€ baseline.yaml        # Standard training
â”‚       â”œâ”€â”€ quantization_aware.yaml  # Progressive quantization
â”‚       â”œâ”€â”€ binary_snn.yaml      # Binary network
â”‚       â””â”€â”€ lightweight.yaml     # Fast prototyping
â”œâ”€â”€ train.py                     # Training script
â”œâ”€â”€ evaluate.py                  # Evaluation script
â”œâ”€â”€ checkpoints/                 # Saved models
â”œâ”€â”€ logs/                        # Training logs
â””â”€â”€ results/                     # Evaluation results
```

## ğŸš€ Getting Started

### 1. Installation

```bash
# Navigate to the project
cd Main_Python

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Dataset Setup

The project uses datasets from the `blink_sim` directory. The expected structure is already set up at:
`../blink_sim/output/train/`

### 3. Training

#### Quick Start (Baseline)
```bash
python train.py --config snn/configs/baseline.yaml
```

#### Quantization-Aware Training
```bash
python train.py --config snn/configs/quantization_aware.yaml
```

#### Binary SNN Training (for FPGA)
```bash
python train.py --config snn/configs/binary_snn.yaml
```

#### Fast Prototyping (Lightweight)
```bash
python train.py --config snn/configs/lightweight.yaml
```

### 4. Evaluation

```bash
python evaluate.py \
  --checkpoint ./checkpoints/best_model.pth \
  --split train \
  --output-dir ./results \
  --save-visualizations
```

### 5. Monitoring Training

```bash
# Launch tensorboard
tensorboard --logdir ./logs
```

## ğŸ”§ Configuration Guide

### Model Types

1. **SpikingFlowNet**: Full-featured model with encoder-decoder architecture
2. **SpikingFlowNetLite**: Lightweight model for FPGA deployment

### Quantization Strategies

#### Progressive Quantization (Recommended)
- Epochs 0-49: 32-bit (full precision)
- Epochs 50-99: 8-bit quantization
- Epochs 100-149: 4-bit quantization  
- Epochs 150+: 2-bit or binary

#### Binary SNN (Extreme Efficiency)
- 1-bit weights and activations
- XNOR-based operations for FPGA
- Minimal power consumption

## ğŸ“Š Key Features

### Quantization-Aware Training
All models support switchable quantization:
- Set `quantization_enabled: true` in config
- Define quantization schedule by epoch
- Progressive bit-width reduction (32â†’8â†’4â†’1)

### Hardware-Ready Design
- Sparsity constraints for power efficiency
- Binary layers for XNOR operations
- Configurable spike rates
- FPGA-friendly architectures

### Comprehensive Metrics
- Endpoint Error (EPE)
- Outlier percentage
- Angular error
- Spike activity statistics

## ğŸ“ Training Tips

### For Best Accuracy
1. Start with baseline configuration
2. Train for 200+ epochs
3. Monitor spike rate (should be 5-15%)

### For FPGA Deployment
1. Use `SpikingFlowNetLite` model
2. Enable quantization-aware training
3. Target low spike rates (<10%)
4. Use binary configuration

## ğŸ“ˆ Expected Performance

| Configuration | Model Size | Spike Rate | FPGA Suitability |
|--------------|------------|------------|------------------|
| Baseline (FP32) | 200 MB | 10% | Low |
| 8-bit QAT | 50 MB | 8% | Medium |
| 4-bit QAT | 25 MB | 7% | High |
| Binary SNN | 6 MB | 5% | Excellent |

## ğŸ› Troubleshooting

### Out of Memory
- Reduce `batch_size`
- Use `SpikingFlowNetLite`
- Reduce `num_timesteps`

### Poor Convergence
- Increase learning rate
- Disable quantization initially
- Reduce `sparsity_weight`

## âœ… Quick Start Checklist

1. âœ“ Project structure created
2. âœ“ Install dependencies: `pip install -r requirements.txt`
3. âœ“ Verify dataset access at `../blink_sim/output/train/`
4. âœ“ Run test training: `python train.py --config snn/configs/lightweight.yaml`
5. âœ“ Monitor with tensorboard: `tensorboard --logdir ./logs`

## ğŸ“ Citation

If you use this code for your research, please cite your thesis.

Good luck with your thesis project! ğŸ“